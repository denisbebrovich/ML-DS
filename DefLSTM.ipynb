{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/denisbebrovich/ML-DS/blob/main/DefLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqwLQJTN74Hb"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "def multivariate_data(dataset, target, start_index, end_index, history_size, target_size, step, single_step=False):\n",
        "  data = []\n",
        "  labels = []\n",
        "  start_index = start_index + history_size\n",
        "  if end_index is None:\n",
        "    end_index = len(dataset) - target_size\n",
        "  print(start_index, end_index, target.shape)\n",
        "  for i in range(start_index, end_index):\n",
        "    indices = range(i-history_size, i, step)\n",
        "    data.append(dataset[indices])\n",
        "\n",
        "    if single_step:\n",
        "      labels.append(target[i+target_size])\n",
        "    else:\n",
        "      labels.append(target[i:i+target_size])\n",
        "\n",
        "  return np.array(data), np.array(labels)\n",
        "\n",
        "def lstm_pred(train, test):\n",
        "  train_array = train.values\n",
        "  train_array = train_array[:, [0, 1, 2]]\n",
        "  test_array = test.values\n",
        "  test_array = test_array[:, [0, 1, 2]]\n",
        "  history_size = 720\n",
        "  target_size = 1\n",
        "  step = 6\n",
        "  TRAIN_SPLIT = len(train_array) * 0.8\n",
        "  tf.random.set_seed(13)\n",
        "  EVALUATION_INTERVAL = 200\n",
        "  EPOCHS = 10\n",
        "\n",
        "  x_train_single, y_train_single = multivariate_data(train_array, train_array, 0,\n",
        "                                                   TRAIN_SPLIT, history_size,\n",
        "                                                   target_size, step,\n",
        "                                                   single_step=True)\n",
        "\n",
        "  x_val_single, y_val_single = multivariate_data(train_array, train_array,\n",
        "                                                   TRAIN_SPLIT, None, history_size,\n",
        "                                                   target_size, step,\n",
        "                                                   single_step=True)\n",
        "\n",
        "  x_test_single, y_test_single = multivariate_data(test_array, test_array,\n",
        "                                               0, None, history_size,\n",
        "                                               target_size, step,\n",
        "                                               single_step=True)\n",
        "\n",
        "  BATCH_SIZE = 256\n",
        "  BUFFER_SIZE = 5000\n",
        "\n",
        "  train_data_single = tf.data.Dataset.from_tensor_slices((x_train_single, y_train_single))\n",
        "  train_data_single = train_data_single.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "\n",
        "  test_data_single = tf.data.Dataset.from_tensor_slices((x_test_single, y_test_single))\n",
        "  test_data_single = test_data_single.batch(BATCH_SIZE).repeat()\n",
        "\n",
        "  val_data_single = tf.data.Dataset.from_tensor_slices((x_val_single, y_val_single))\n",
        "  val_data_single = val_data_single.batch(BATCH_SIZE).repeat()\n",
        "\n",
        "  single_step_model = tf.keras.models.Sequential()\n",
        "  single_step_model.add(tf.keras.layers.LSTM(32, input_shape=x_train_single.shape[-2:]))\n",
        "  single_step_model.add(tf.keras.layers.Dense(3))\n",
        "  single_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='mae')\n",
        "\n",
        "  single_step_history = single_step_model.fit(train_data_single, epochs=EPOCHS,\n",
        "                                            steps_per_epoch=EVALUATION_INTERVAL,\n",
        "                                            validation_data=val_data_single,\n",
        "                                            validation_steps=50)\n",
        "  predict = single_step_model.predict(x_train_single)\n",
        "  train_predict = single_step_model.predict(x_train_single)\n",
        "\n",
        "  train_abs_Dif = np.array(abs(train_predict - y_train_single))\n",
        "  train_abs_Dif_sum = train_abs_Dif.sum(axis = 1)\n",
        "  treshold = np.amax(train_abs_Dif_sum, axis = None)\n",
        "  test_predict = single_step_model.predict(x_test_single)\n",
        "  test_abs_Dif_sum = test_abs_Dif.sum(axis = 1)\n",
        "\n",
        "  returned_arr = np.array(list(map(lambda x: int(x > treshold), test_abs_Dif_sum)))\n",
        "  returned_arr[returned_arr == 1] = -1\n",
        "  returned_arr[returned_arr == 0] = 1\n",
        "\n",
        "  zeros = np.zeros((720,), dtype=int)\n",
        "  zeros[zeros == 0] = 1\n",
        "  returner = np.concatenate((zeros, returned_arr), axis=None)\n",
        "  return returner"
      ]
    }
  ]
}